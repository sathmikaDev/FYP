import lightning.pytorch as pl
from lightning.pytorch.loggers import TensorBoardLogger
from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor
# import dataset, network to train and metric to optimize
from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, QuantileLoss, GroupNormalizer
from lightning.pytorch.tuner import Tuner
import torch
from pytorch_forecasting.metrics import MAE,MAPE, MASE
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


import torch
print(torch.cuda.is_available())  # Should return True
print(torch.cuda.get_device_name(0))  # Should print your GPU name


# Import the dataset
crypto_prices_exogenous = pd.read_csv('./crypto_prices_exogenous.csv')


crypto_prices_exogenous.head()


crypto_prices_exogenous = crypto_prices_exogenous.drop(columns=['ETH_Price', 'ETH_Price', 'ETH_Market_Cap', 'XRP_Price', 'XRP_Market_Cap'], axis=1)





# Select only numeric columns for correlation analysis
df_numeric = crypto_prices_exogenous.select_dtypes(include=['number'])

# Compute the correlation matrix
corr_matrix = df_numeric.corr()

# Extract correlation values for BTC_Price
btc_correlation = corr_matrix["BTC_Price"].sort_values(ascending=False)

# Display correlation values
print(btc_correlation)

# Visualizing the correlation matrix as a heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm", linewidths=0.5)
plt.title("Correlation Heatmap")
plt.show()


# drop unwanted features
crypto_prices_exogenous.drop(columns=['interest_rate', 'us_10_year_bond_yield', 'us_dollar_index', 'vix_value', 'usdt_Price'], inplace=True)


crypto_prices_exogenous.head()


from sklearn.preprocessing import MinMaxScaler

# Initialize and fit the scaler
scaler = MinMaxScaler()
crypto_prices_exogenous_scaled = crypto_prices_exogenous.copy()
numeric_cols = ['BTC_Price', 'BTC_Market_Cap', 'Gold_Price', 'IGREA', 'NASDAQ_Price', 'SP_500_Price']
crypto_prices_exogenous_scaled[numeric_cols] = scaler.fit_transform(crypto_prices_exogenous[numeric_cols])


crypto_prices_exogenous_scaled.head()


crypto_prices_exogenous_scaled['id'] = "BTC"


crypto_prices_exogenous_scaled.dtypes


crypto_prices_exogenous_scaled['Date'] = pd.to_datetime(crypto_prices_exogenous_scaled['Date'])


# add additional features
crypto_prices_exogenous_scaled["month"] = crypto_prices_exogenous_scaled.Date.dt.month.astype(str).astype("category")  # categories have be strings
crypto_prices_exogenous_scaled["day_of_week"] = crypto_prices_exogenous_scaled.Date.dt.dayofweek.astype(str).astype("category")
crypto_prices_exogenous_scaled["day_of_year"] = crypto_prices_exogenous_scaled.Date.dt.dayofyear.astype(str).astype("category")
crypto_prices_exogenous_scaled["quarter"] = crypto_prices_exogenous_scaled.Date.dt.quarter.astype(str).astype("category")  # categories have be strings


crypto_prices_exogenous_scaled.head()


# create time index column
crypto_prices_exogenous_scaled['time_idx'] = crypto_prices_exogenous_scaled.index


max_prediction_length = 7  # Set to desired prediction length
max_encoder_length = 30  # Set to desired history length (e.g., 30 days) - pass 30 days are used to predict next 7 days
batch_size = 128 # changed from 64-> 128
training_cutoff = crypto_prices_exogenous_scaled['time_idx'].max() - max_prediction_length


training = TimeSeriesDataSet(
    crypto_prices_exogenous_scaled[lambda x: x.time_idx <= training_cutoff],
    time_idx="time_idx",
    target="BTC_Price",
    group_ids=["id"],  # Use "id" as the group identifier
    max_encoder_length=max_encoder_length // 2,
    max_prediction_length=max_prediction_length,
    static_categoricals=["id"],
    time_varying_known_categoricals=["month", "day_of_week", "day_of_year", "quarter"],
    static_reals=[],  # Add any static features if available
    time_varying_known_reals=["time_idx", "BTC_Market_Cap","Gold_Price","IGREA","NASDAQ_Price","SP_500_Price"],
    time_varying_unknown_categoricals=[],
    time_varying_unknown_reals=["BTC_Price"],
    target_normalizer=GroupNormalizer(groups=["id"]),
    add_relative_time_idx=True,
    add_target_scales=True,
    add_encoder_length=True,
)


validation = TimeSeriesDataSet.from_dataset(training, crypto_prices_exogenous_scaled, min_prediction_idx=training.index.time.max() + 1, stop_randomization=True)


# create data loaders
train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=2)
val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=2)


early_stop_callback = EarlyStopping(monitor="val_loss", min_delta=1e-3, patience=20, verbose=False, mode="min")
lr_logger = LearningRateMonitor()
trainer = pl.Trainer(
    max_epochs=300,
    accelerator="gpu",  # run on CPU, if on multiple GPUs, use strategy="ddp"
    gradient_clip_val=0.1,
    limit_train_batches=128,  # 30 batches per epoch
    callbacks=[lr_logger, early_stop_callback],
    logger=TensorBoardLogger("lightning_logs")
)


tft = TemporalFusionTransformer.from_dataset(
    # dataset
    training,
    # architecture hyperparameters
    hidden_size=128,
    attention_head_size=4,
    dropout=0.1,
    hidden_continuous_size=32,
    # loss metric to optimize
    loss=QuantileLoss(),
    # logging frequency
    log_interval=2,
    # optimizer parameters
    learning_rate=0.002,
    reduce_on_plateau_patience=2
)
print(f"Number of parameters in network: {tft.size()/1e3:.1f}k")


trainer.fit(
    tft, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader,
)



