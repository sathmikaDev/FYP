{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-forecasting in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from pytorch-forecasting) (1.26.4)\n",
      "Requirement already satisfied: torch!=2.0.1,<3.0.0,>=2.0.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from pytorch-forecasting) (2.5.1)\n",
      "Requirement already satisfied: lightning<3.0.0,>=2.0.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from pytorch-forecasting) (2.4.0)\n",
      "Requirement already satisfied: scipy<2.0,>=1.8 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from pytorch-forecasting) (1.13.1)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.3.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from pytorch-forecasting) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn<2.0,>=1.2 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from pytorch-forecasting) (1.4.2)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.1)\n",
      "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2024.3.1)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (0.11.8)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (24.1)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.5.1)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.11.0)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (2.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.9.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch-forecasting) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from tqdm<6.0,>=4.57.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jinja2->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (2.1.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.9.3)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (7.8.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.6 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from ipywidgets) (3.6.6)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (8.29.0)\n",
      "Requirement already satisfied: jupyterlab-widgets<3,>=1.0.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=4.0.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=4.0.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=4.0.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=4.0.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.6.6->ipywidgets) (7.2.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.3,>=4.2.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (4.2.5)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=4.0.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (3.1.4)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (7.10.0)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (5.9.2)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (7.4.0)\n",
      "Requirement already satisfied: packaging>=22.0 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (24.1)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.14.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.0.10)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (26.2.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.26.0)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (6.29.5)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (72.1.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (4.19.2)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.32.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from babel>=2.10->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2024.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.14.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel>=6.5.0->jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.8.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel>=6.5.0->jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from ipykernel>=6.5.0->jupyterlab<4.3,>=4.2.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (6.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (4.3.6)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (308)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.2.2)\n",
      "Requirement already satisfied: webencodings in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (0.5.1)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets)\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets)\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.1)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets)\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=1.11 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets)\n",
      "  Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.6->ipywidgets) (1.2.3)\n",
      "Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webcolors, uri-template, fqdn, isoduration\n",
      "Successfully installed fqdn-1.5.1 isoduration-20.11.0 uri-template-1.3.0 webcolors-24.11.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dollar_Index = pd.read_csv(\"../Datasetsv2/preprocessed/Dollar_Index_Preprocessed.csv\")\n",
    "Gold = pd.read_csv(\"../Datasetsv2/preprocessed/Gold_Preprocessed.csv\")\n",
    "Interest_Rate = pd.read_csv(\"../Datasetsv2/preprocessed/Interest_Rate_Preprocessed.csv\")\n",
    "US_10_Year = pd.read_csv(\"../Datasetsv2/preprocessed/US_10_Year_Preprocessed.csv\")\n",
    "VIX_Data = pd.read_csv(\"../Datasetsv2/preprocessed/VIX_Data_Preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>VIX_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>19.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>20.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  VIX_Value\n",
       "0  2015-01-09      17.55\n",
       "1  2015-01-10      17.55\n",
       "2  2015-01-11      17.55\n",
       "3  2015-01-12      19.60\n",
       "4  2015-01-13      20.56"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIX_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exogenous_Variables = Dollar_Index.merge(Gold, on=\"Date\", how=\"outer\") \\\n",
    "                        .merge(Interest_Rate, on=\"Date\", how=\"outer\") \\\n",
    "                        .merge(US_10_Year, on=\"Date\", how=\"outer\") \\\n",
    "                        .merge(VIX_Data, on=\"Date\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Dollar_Index</th>\n",
       "      <th>Gold_Price</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>US_10_Year</th>\n",
       "      <th>VIX_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>91.940002</td>\n",
       "      <td>1211.2500</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.950</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>91.940002</td>\n",
       "      <td>1211.2500</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.950</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>91.940002</td>\n",
       "      <td>1211.2500</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.950</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>91.980003</td>\n",
       "      <td>1222.0000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.909</td>\n",
       "      <td>19.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>92.309998</td>\n",
       "      <td>1239.0000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.905</td>\n",
       "      <td>20.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>2025-01-05</td>\n",
       "      <td>108.949997</td>\n",
       "      <td>2640.1664</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.601</td>\n",
       "      <td>16.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>108.260002</td>\n",
       "      <td>2635.8796</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.623</td>\n",
       "      <td>16.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>108.540001</td>\n",
       "      <td>2648.7119</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.684</td>\n",
       "      <td>17.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>109.089996</td>\n",
       "      <td>2661.5352</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.692</td>\n",
       "      <td>17.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>2025-01-09</td>\n",
       "      <td>109.180000</td>\n",
       "      <td>2669.9489</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.688</td>\n",
       "      <td>18.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3654 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Dollar_Index  Gold_Price  Interest_Rate  US_10_Year  \\\n",
       "0     2015-01-09     91.940002   1211.2500           0.12       1.950   \n",
       "1     2015-01-10     91.940002   1211.2500           0.12       1.950   \n",
       "2     2015-01-11     91.940002   1211.2500           0.12       1.950   \n",
       "3     2015-01-12     91.980003   1222.0000           0.12       1.909   \n",
       "4     2015-01-13     92.309998   1239.0000           0.12       1.905   \n",
       "...          ...           ...         ...            ...         ...   \n",
       "3649  2025-01-05    108.949997   2640.1664           4.33       4.601   \n",
       "3650  2025-01-06    108.260002   2635.8796           4.33       4.623   \n",
       "3651  2025-01-07    108.540001   2648.7119           4.33       4.684   \n",
       "3652  2025-01-08    109.089996   2661.5352           4.33       4.692   \n",
       "3653  2025-01-09    109.180000   2669.9489           4.33       4.688   \n",
       "\n",
       "      VIX_Value  \n",
       "0         17.55  \n",
       "1         17.55  \n",
       "2         17.55  \n",
       "3         19.60  \n",
       "4         20.56  \n",
       "...         ...  \n",
       "3649      16.13  \n",
       "3650      16.04  \n",
       "3651      17.82  \n",
       "3652      17.70  \n",
       "3653      18.07  \n",
       "\n",
       "[3654 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Exogenous_Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'date' as index\n",
    "Exogenous_Variables.set_index(\"Date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merged dataset\n",
    "Exogenous_Variables.to_csv(\"../Datasetsv2/Exogenous/Exogenous_Variables.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# download bitcoin data\n",
    "start_date = \"2015-01-09\"\n",
    "end_date = \"2025-01-10\"\n",
    "BTC_USD = yf.download(\"BTC-USD\", start=start_date, end=end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "      <th>BTC-USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-09</th>\n",
       "      <td>290.407990</td>\n",
       "      <td>291.114014</td>\n",
       "      <td>280.532990</td>\n",
       "      <td>282.382996</td>\n",
       "      <td>18718600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-10</th>\n",
       "      <td>274.795990</td>\n",
       "      <td>288.127014</td>\n",
       "      <td>273.966003</td>\n",
       "      <td>287.303009</td>\n",
       "      <td>15264300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-11</th>\n",
       "      <td>265.660004</td>\n",
       "      <td>279.638000</td>\n",
       "      <td>265.039001</td>\n",
       "      <td>274.608002</td>\n",
       "      <td>18200800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-12</th>\n",
       "      <td>267.795990</td>\n",
       "      <td>272.203003</td>\n",
       "      <td>265.200012</td>\n",
       "      <td>266.145996</td>\n",
       "      <td>18880300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-13</th>\n",
       "      <td>225.860992</td>\n",
       "      <td>268.277008</td>\n",
       "      <td>219.906006</td>\n",
       "      <td>267.394012</td>\n",
       "      <td>72843904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-05</th>\n",
       "      <td>98314.960938</td>\n",
       "      <td>98813.304688</td>\n",
       "      <td>97291.765625</td>\n",
       "      <td>98233.906250</td>\n",
       "      <td>20525254825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-06</th>\n",
       "      <td>102078.085938</td>\n",
       "      <td>102482.875000</td>\n",
       "      <td>97926.148438</td>\n",
       "      <td>98314.953125</td>\n",
       "      <td>51823432705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-07</th>\n",
       "      <td>96922.703125</td>\n",
       "      <td>102712.484375</td>\n",
       "      <td>96132.875000</td>\n",
       "      <td>102248.851562</td>\n",
       "      <td>58685738547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-08</th>\n",
       "      <td>95043.523438</td>\n",
       "      <td>97258.320312</td>\n",
       "      <td>92525.843750</td>\n",
       "      <td>96924.164062</td>\n",
       "      <td>63875859171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-09</th>\n",
       "      <td>92484.039062</td>\n",
       "      <td>95349.718750</td>\n",
       "      <td>91220.843750</td>\n",
       "      <td>95043.484375</td>\n",
       "      <td>62777261693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3654 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price               Close           High           Low           Open  \\\n",
       "Ticker            BTC-USD        BTC-USD       BTC-USD        BTC-USD   \n",
       "Date                                                                    \n",
       "2015-01-09     290.407990     291.114014    280.532990     282.382996   \n",
       "2015-01-10     274.795990     288.127014    273.966003     287.303009   \n",
       "2015-01-11     265.660004     279.638000    265.039001     274.608002   \n",
       "2015-01-12     267.795990     272.203003    265.200012     266.145996   \n",
       "2015-01-13     225.860992     268.277008    219.906006     267.394012   \n",
       "...                   ...            ...           ...            ...   \n",
       "2025-01-05   98314.960938   98813.304688  97291.765625   98233.906250   \n",
       "2025-01-06  102078.085938  102482.875000  97926.148438   98314.953125   \n",
       "2025-01-07   96922.703125  102712.484375  96132.875000  102248.851562   \n",
       "2025-01-08   95043.523438   97258.320312  92525.843750   96924.164062   \n",
       "2025-01-09   92484.039062   95349.718750  91220.843750   95043.484375   \n",
       "\n",
       "Price            Volume  \n",
       "Ticker          BTC-USD  \n",
       "Date                     \n",
       "2015-01-09     18718600  \n",
       "2015-01-10     15264300  \n",
       "2015-01-11     18200800  \n",
       "2015-01-12     18880300  \n",
       "2015-01-13     72843904  \n",
       "...                 ...  \n",
       "2025-01-05  20525254825  \n",
       "2025-01-06  51823432705  \n",
       "2025-01-07  58685738547  \n",
       "2025-01-08  63875859171  \n",
       "2025-01-09  62777261693  \n",
       "\n",
       "[3654 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BTC_USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any missing values? False\n"
     ]
    }
   ],
   "source": [
    "# check for missing values\n",
    "BTC_USD_Missing = BTC_USD.isnull().any().any()\n",
    "print(f\"Are there any missing values? {BTC_USD_Missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BTC_USD.rename(columns={'Close': 'BTC_Price'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BTC_USD = BTC_USD.drop(columns=['High', 'Low', 'Open', 'Volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Price      Ticker \n",
       "BTC_Price  BTC-USD    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BTC_USD.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>BTC_Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-09</th>\n",
       "      <td>290.407990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-10</th>\n",
       "      <td>274.795990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-11</th>\n",
       "      <td>265.660004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-12</th>\n",
       "      <td>267.795990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-13</th>\n",
       "      <td>225.860992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price        BTC_Price\n",
       "Date                  \n",
       "2015-01-09  290.407990\n",
       "2015-01-10  274.795990\n",
       "2015-01-11  265.660004\n",
       "2015-01-12  267.795990\n",
       "2015-01-13  225.860992"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BTC_USD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BTC_USD.columns = BTC_USD.columns.droplevel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BTC_USD.to_csv(\"BTC_USD.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BTC_USD = pd.read_csv('../Datasetsv2/BTC_USD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BTC_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>290.407990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>274.795990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>265.660004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>267.795990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>225.860992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   BTC_Price\n",
       "0  2015-01-09  290.407990\n",
       "1  2015-01-10  274.795990\n",
       "2  2015-01-11  265.660004\n",
       "3  2015-01-12  267.795990\n",
       "4  2015-01-13  225.860992"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BTC_USD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BTC_USD['Date'] = pd.to_datetime(BTC_USD['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BTC_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3654</td>\n",
       "      <td>3654.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2020-01-09 12:00:00</td>\n",
       "      <td>20376.264433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2015-01-09 00:00:00</td>\n",
       "      <td>178.102997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2017-07-10 06:00:00</td>\n",
       "      <td>2668.765015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2020-01-09 12:00:00</td>\n",
       "      <td>9713.667480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2022-07-10 18:00:00</td>\n",
       "      <td>32863.615234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025-01-09 00:00:00</td>\n",
       "      <td>106140.601562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22500.082535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date      BTC_Price\n",
       "count                 3654    3654.000000\n",
       "mean   2020-01-09 12:00:00   20376.264433\n",
       "min    2015-01-09 00:00:00     178.102997\n",
       "25%    2017-07-10 06:00:00    2668.765015\n",
       "50%    2020-01-09 12:00:00    9713.667480\n",
       "75%    2022-07-10 18:00:00   32863.615234\n",
       "max    2025-01-09 00:00:00  106140.601562\n",
       "std                    NaN   22500.082535"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BTC_USD.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BTC_USD.to_csv('../Datasetsv2/preprocessed/BTC_USD_Preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now import the preprocessed BTC data set\n",
    "BTC_USD_Final = pd.read_csv(\"../Datasetsv2/preprocessed/BTC_USD_Preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import exogenous variables dataset\n",
    "Exogenous_Variables_Final = pd.read_csv(\"../Datasetsv2/Exogenous/Exogenous_Variables.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine both datasets\n",
    "Final_Dataset = BTC_USD_Final.merge(Exogenous_Variables_Final, on=\"Date\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BTC_Price</th>\n",
       "      <th>Dollar_Index</th>\n",
       "      <th>Gold_Price</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>US_10_Year</th>\n",
       "      <th>VIX_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>290.407990</td>\n",
       "      <td>91.940002</td>\n",
       "      <td>1211.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.950</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>274.795990</td>\n",
       "      <td>91.940002</td>\n",
       "      <td>1211.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.950</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>265.660004</td>\n",
       "      <td>91.940002</td>\n",
       "      <td>1211.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.950</td>\n",
       "      <td>17.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>267.795990</td>\n",
       "      <td>91.980003</td>\n",
       "      <td>1222.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.909</td>\n",
       "      <td>19.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>225.860992</td>\n",
       "      <td>92.309998</td>\n",
       "      <td>1239.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.905</td>\n",
       "      <td>20.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   BTC_Price  Dollar_Index  Gold_Price  Interest_Rate  \\\n",
       "0  2015-01-09  290.407990     91.940002     1211.25           0.12   \n",
       "1  2015-01-10  274.795990     91.940002     1211.25           0.12   \n",
       "2  2015-01-11  265.660004     91.940002     1211.25           0.12   \n",
       "3  2015-01-12  267.795990     91.980003     1222.00           0.12   \n",
       "4  2015-01-13  225.860992     92.309998     1239.00           0.12   \n",
       "\n",
       "   US_10_Year  VIX_Value  \n",
       "0       1.950      17.55  \n",
       "1       1.950      17.55  \n",
       "2       1.950      17.55  \n",
       "3       1.909      19.60  \n",
       "4       1.905      20.56  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a csv\n",
    "Final_Dataset.to_csv('../Datasetsv2/FinalDataset/Final_Dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x=Final_Dataset[\"BTC_Price\"])\n",
    "plt.title(\"Box Plot of Bitcoin Prices\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.2.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from optuna) (2.0.30)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from optuna) (4.66.4)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sathmika\\appdata\\roaming\\python\\python312\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\sathmika\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Downloading optuna-4.2.0-py3-none-any.whl (383 kB)\n",
      "   ---------------------------------------- 0.0/383.4 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 41.0/383.4 kB 653.6 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 153.6/383.4 kB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 348.2/383.4 kB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 383.4/383.4 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
      "   ---------------------------------------- 0.0/233.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 233.6/233.6 kB 7.2 MB/s eta 0:00:00\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.6/78.6 kB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: Mako, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.8 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import pytorch_lightning as pl\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet, Baseline\n",
    "from pytorch_forecasting.metrics import MAE, RMSE, MAPE, PoissonLoss, QuantileLoss\n",
    "import pytorch_forecasting\n",
    "import optuna\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from pytorch_forecasting.data.encoders import NaNLabelEncoder\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.tuner import Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import saved cdv\n",
    "Final_Dataset = pd.read_csv(\"../Datasetsv2/FinalDataset/Final_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date              object\n",
       "BTC_Price        float64\n",
       "Dollar_Index     float64\n",
       "Gold_Price       float64\n",
       "Interest_Rate    float64\n",
       "US_10_Year       float64\n",
       "VIX_Value        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Dataset['Date'] = pd.to_datetime(Final_Dataset['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Dataset['id'] = \"BTC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BTC_Price</th>\n",
       "      <th>Dollar_Index</th>\n",
       "      <th>Gold_Price</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>US_10_Year</th>\n",
       "      <th>VIX_Value</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>290.407990</td>\n",
       "      <td>91.940002</td>\n",
       "      <td>1211.2500</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.950</td>\n",
       "      <td>17.55</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>274.795990</td>\n",
       "      <td>91.940002</td>\n",
       "      <td>1211.2500</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.950</td>\n",
       "      <td>17.55</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>265.660004</td>\n",
       "      <td>91.940002</td>\n",
       "      <td>1211.2500</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.950</td>\n",
       "      <td>17.55</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>267.795990</td>\n",
       "      <td>91.980003</td>\n",
       "      <td>1222.0000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.909</td>\n",
       "      <td>19.60</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>225.860992</td>\n",
       "      <td>92.309998</td>\n",
       "      <td>1239.0000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.905</td>\n",
       "      <td>20.56</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>2025-01-05</td>\n",
       "      <td>98314.960938</td>\n",
       "      <td>108.949997</td>\n",
       "      <td>2640.1664</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.601</td>\n",
       "      <td>16.13</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>102078.085938</td>\n",
       "      <td>108.260002</td>\n",
       "      <td>2635.8796</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.623</td>\n",
       "      <td>16.04</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>96922.703125</td>\n",
       "      <td>108.540001</td>\n",
       "      <td>2648.7119</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.684</td>\n",
       "      <td>17.82</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>95043.523438</td>\n",
       "      <td>109.089996</td>\n",
       "      <td>2661.5352</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.692</td>\n",
       "      <td>17.70</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>2025-01-09</td>\n",
       "      <td>92484.039062</td>\n",
       "      <td>109.180000</td>\n",
       "      <td>2669.9489</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.688</td>\n",
       "      <td>18.07</td>\n",
       "      <td>BTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3654 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      BTC_Price  Dollar_Index  Gold_Price  Interest_Rate  \\\n",
       "0    2015-01-09     290.407990     91.940002   1211.2500           0.12   \n",
       "1    2015-01-10     274.795990     91.940002   1211.2500           0.12   \n",
       "2    2015-01-11     265.660004     91.940002   1211.2500           0.12   \n",
       "3    2015-01-12     267.795990     91.980003   1222.0000           0.12   \n",
       "4    2015-01-13     225.860992     92.309998   1239.0000           0.12   \n",
       "...         ...            ...           ...         ...            ...   \n",
       "3649 2025-01-05   98314.960938    108.949997   2640.1664           4.33   \n",
       "3650 2025-01-06  102078.085938    108.260002   2635.8796           4.33   \n",
       "3651 2025-01-07   96922.703125    108.540001   2648.7119           4.33   \n",
       "3652 2025-01-08   95043.523438    109.089996   2661.5352           4.33   \n",
       "3653 2025-01-09   92484.039062    109.180000   2669.9489           4.33   \n",
       "\n",
       "      US_10_Year  VIX_Value   id  \n",
       "0          1.950      17.55  BTC  \n",
       "1          1.950      17.55  BTC  \n",
       "2          1.950      17.55  BTC  \n",
       "3          1.909      19.60  BTC  \n",
       "4          1.905      20.56  BTC  \n",
       "...          ...        ...  ...  \n",
       "3649       4.601      16.13  BTC  \n",
       "3650       4.623      16.04  BTC  \n",
       "3651       4.684      17.82  BTC  \n",
       "3652       4.692      17.70  BTC  \n",
       "3653       4.688      18.07  BTC  \n",
       "\n",
       "[3654 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset parameters\n",
    "Final_Dataset['time_idx'] = Final_Dataset.index\n",
    "max_prediction_length = 7  # Set to desired prediction length\n",
    "max_encoder_length = 30  # Set to desired history length (e.g., 30 days) - pass 30 days are used to predict next 7 days\n",
    "batch_size = 64\n",
    "training_cutoff = Final_Dataset['time_idx'].max() - max_prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BTC_Price</th>\n",
       "      <th>Dollar_Index</th>\n",
       "      <th>Gold_Price</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>US_10_Year</th>\n",
       "      <th>VIX_Value</th>\n",
       "      <th>id</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>290.407990</td>\n",
       "      <td>91.940002</td>\n",
       "      <td>1211.2500</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.950</td>\n",
       "      <td>17.55</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>274.795990</td>\n",
       "      <td>91.940002</td>\n",
       "      <td>1211.2500</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.950</td>\n",
       "      <td>17.55</td>\n",
       "      <td>BTC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>265.660004</td>\n",
       "      <td>91.940002</td>\n",
       "      <td>1211.2500</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.950</td>\n",
       "      <td>17.55</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>267.795990</td>\n",
       "      <td>91.980003</td>\n",
       "      <td>1222.0000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.909</td>\n",
       "      <td>19.60</td>\n",
       "      <td>BTC</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>225.860992</td>\n",
       "      <td>92.309998</td>\n",
       "      <td>1239.0000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.905</td>\n",
       "      <td>20.56</td>\n",
       "      <td>BTC</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>2025-01-05</td>\n",
       "      <td>98314.960938</td>\n",
       "      <td>108.949997</td>\n",
       "      <td>2640.1664</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.601</td>\n",
       "      <td>16.13</td>\n",
       "      <td>BTC</td>\n",
       "      <td>3649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>102078.085938</td>\n",
       "      <td>108.260002</td>\n",
       "      <td>2635.8796</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.623</td>\n",
       "      <td>16.04</td>\n",
       "      <td>BTC</td>\n",
       "      <td>3650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>96922.703125</td>\n",
       "      <td>108.540001</td>\n",
       "      <td>2648.7119</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.684</td>\n",
       "      <td>17.82</td>\n",
       "      <td>BTC</td>\n",
       "      <td>3651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>95043.523438</td>\n",
       "      <td>109.089996</td>\n",
       "      <td>2661.5352</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.692</td>\n",
       "      <td>17.70</td>\n",
       "      <td>BTC</td>\n",
       "      <td>3652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>2025-01-09</td>\n",
       "      <td>92484.039062</td>\n",
       "      <td>109.180000</td>\n",
       "      <td>2669.9489</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.688</td>\n",
       "      <td>18.07</td>\n",
       "      <td>BTC</td>\n",
       "      <td>3653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3654 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      BTC_Price  Dollar_Index  Gold_Price  Interest_Rate  \\\n",
       "0    2015-01-09     290.407990     91.940002   1211.2500           0.12   \n",
       "1    2015-01-10     274.795990     91.940002   1211.2500           0.12   \n",
       "2    2015-01-11     265.660004     91.940002   1211.2500           0.12   \n",
       "3    2015-01-12     267.795990     91.980003   1222.0000           0.12   \n",
       "4    2015-01-13     225.860992     92.309998   1239.0000           0.12   \n",
       "...         ...            ...           ...         ...            ...   \n",
       "3649 2025-01-05   98314.960938    108.949997   2640.1664           4.33   \n",
       "3650 2025-01-06  102078.085938    108.260002   2635.8796           4.33   \n",
       "3651 2025-01-07   96922.703125    108.540001   2648.7119           4.33   \n",
       "3652 2025-01-08   95043.523438    109.089996   2661.5352           4.33   \n",
       "3653 2025-01-09   92484.039062    109.180000   2669.9489           4.33   \n",
       "\n",
       "      US_10_Year  VIX_Value   id  time_idx  \n",
       "0          1.950      17.55  BTC         0  \n",
       "1          1.950      17.55  BTC         1  \n",
       "2          1.950      17.55  BTC         2  \n",
       "3          1.909      19.60  BTC         3  \n",
       "4          1.905      20.56  BTC         4  \n",
       "...          ...        ...  ...       ...  \n",
       "3649       4.601      16.13  BTC      3649  \n",
       "3650       4.623      16.04  BTC      3650  \n",
       "3651       4.684      17.82  BTC      3651  \n",
       "3652       4.692      17.70  BTC      3652  \n",
       "3653       4.688      18.07  BTC      3653  \n",
       "\n",
       "[3654 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>BTC_Price</th>\n",
       "      <th>Dollar_Index</th>\n",
       "      <th>Gold_Price</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>US_10_Year</th>\n",
       "      <th>VIX_Value</th>\n",
       "      <th>id</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>290.407990</td>\n",
       "      <td>91.940002</td>\n",
       "      <td>1211.2500</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.950</td>\n",
       "      <td>17.55</td>\n",
       "      <td>BTC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>274.795990</td>\n",
       "      <td>91.940002</td>\n",
       "      <td>1211.2500</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.950</td>\n",
       "      <td>17.55</td>\n",
       "      <td>BTC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>265.660004</td>\n",
       "      <td>91.940002</td>\n",
       "      <td>1211.2500</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.950</td>\n",
       "      <td>17.55</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>267.795990</td>\n",
       "      <td>91.980003</td>\n",
       "      <td>1222.0000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.909</td>\n",
       "      <td>19.60</td>\n",
       "      <td>BTC</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>225.860992</td>\n",
       "      <td>92.309998</td>\n",
       "      <td>1239.0000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.905</td>\n",
       "      <td>20.56</td>\n",
       "      <td>BTC</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>2025-01-05</td>\n",
       "      <td>98314.960938</td>\n",
       "      <td>108.949997</td>\n",
       "      <td>2640.1664</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.601</td>\n",
       "      <td>16.13</td>\n",
       "      <td>BTC</td>\n",
       "      <td>3649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>102078.085938</td>\n",
       "      <td>108.260002</td>\n",
       "      <td>2635.8796</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.623</td>\n",
       "      <td>16.04</td>\n",
       "      <td>BTC</td>\n",
       "      <td>3650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>2025-01-07</td>\n",
       "      <td>96922.703125</td>\n",
       "      <td>108.540001</td>\n",
       "      <td>2648.7119</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.684</td>\n",
       "      <td>17.82</td>\n",
       "      <td>BTC</td>\n",
       "      <td>3651</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>95043.523438</td>\n",
       "      <td>109.089996</td>\n",
       "      <td>2661.5352</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.692</td>\n",
       "      <td>17.70</td>\n",
       "      <td>BTC</td>\n",
       "      <td>3652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>2025-01-09</td>\n",
       "      <td>92484.039062</td>\n",
       "      <td>109.180000</td>\n",
       "      <td>2669.9489</td>\n",
       "      <td>4.33</td>\n",
       "      <td>4.688</td>\n",
       "      <td>18.07</td>\n",
       "      <td>BTC</td>\n",
       "      <td>3653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3654 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      BTC_Price  Dollar_Index  Gold_Price  Interest_Rate  \\\n",
       "0    2015-01-09     290.407990     91.940002   1211.2500           0.12   \n",
       "1    2015-01-10     274.795990     91.940002   1211.2500           0.12   \n",
       "2    2015-01-11     265.660004     91.940002   1211.2500           0.12   \n",
       "3    2015-01-12     267.795990     91.980003   1222.0000           0.12   \n",
       "4    2015-01-13     225.860992     92.309998   1239.0000           0.12   \n",
       "...         ...            ...           ...         ...            ...   \n",
       "3649 2025-01-05   98314.960938    108.949997   2640.1664           4.33   \n",
       "3650 2025-01-06  102078.085938    108.260002   2635.8796           4.33   \n",
       "3651 2025-01-07   96922.703125    108.540001   2648.7119           4.33   \n",
       "3652 2025-01-08   95043.523438    109.089996   2661.5352           4.33   \n",
       "3653 2025-01-09   92484.039062    109.180000   2669.9489           4.33   \n",
       "\n",
       "      US_10_Year  VIX_Value   id  time_idx month  \n",
       "0          1.950      17.55  BTC         0     1  \n",
       "1          1.950      17.55  BTC         1     1  \n",
       "2          1.950      17.55  BTC         2     1  \n",
       "3          1.909      19.60  BTC         3     1  \n",
       "4          1.905      20.56  BTC         4     1  \n",
       "...          ...        ...  ...       ...   ...  \n",
       "3649       4.601      16.13  BTC      3649     1  \n",
       "3650       4.623      16.04  BTC      3650     1  \n",
       "3651       4.684      17.82  BTC      3651     1  \n",
       "3652       4.692      17.70  BTC      3652     1  \n",
       "3653       4.688      18.07  BTC      3653     1  \n",
       "\n",
       "[3654 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add additional features\n",
    "Final_Dataset[\"month\"] = Final_Dataset.Date.dt.month.astype(str).astype(\"category\")  # categories have be strings\n",
    "\n",
    "Final_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in 'time_idx': 0\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in the 'time_idx' column\n",
    "nan_time_idx = Final_Dataset['time_idx'].isnull().sum()\n",
    "print(f\"NaN values in 'time_idx': {nan_time_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    Final_Dataset[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"BTC_Price\",\n",
    "    group_ids=[\"id\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[],\n",
    "    time_varying_known_reals=list(Final_Dataset.columns.difference(['BTC_Price', 'time_idx', 'id'])),\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\"BTC_Price\"],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"id\"], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, Final_Dataset, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 64  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sathmika\\AppData\\Local\\Temp\\ipykernel_18548\\2174382858.py:2: UserWarning: In pytorch-forecasting models, on versions 1.1.X, the default optimizer defaults to 'adam', if pytorch_optimizer is not installed, otherwise it defaults to 'ranger' from pytorch_optimizer. From version 1.2.0, the default optimizer will be 'adam' regardless of whether pytorch_optimizer is installed, in order to minimize the number of dependencies in default parameter settings. Users who wish to ensure their code continues using 'ranger' as optimizer should ensure that pytorch_optimizer is installed, and set the optimizer parameter explicitly to 'ranger'.\n",
      "  baseline_predictions = Baseline().predict(val_dataloader, return_y=True)\n",
      "C:\\Users\\Sathmika\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "C:\\Users\\Sathmika\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "C:\\Users\\Sathmika\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2210.1741)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "baseline_predictions = Baseline().predict(val_dataloader, return_y=True)\n",
    "MAE()(baseline_predictions.output, baseline_predictions.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Sathmika\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "C:\\Users\\Sathmika\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "C:\\Users\\Sathmika\\anaconda3\\Lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\__init__.py:143: UserWarning: In pytorch-forecasting models, on versions 1.1.X, the default optimizer defaults to 'adam', if pytorch_optimizer is not installed, otherwise it defaults to 'ranger' from pytorch_optimizer. From version 1.2.0, the default optimizer will be 'adam' regardless of whether pytorch_optimizer is installed, in order to minimize the number of dependencies in default parameter settings. Users who wish to ensure their code continues using 'ranger' as optimizer should ensure that pytorch_optimizer is installed, and set the optimizer parameter explicitly to 'ranger'.\n",
      "  super().__init__(loss=loss, logging_metrics=logging_metrics, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 12.0k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=8,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    loss=QuantileLoss(),\n",
    "    # optimizer=\"Ranger\", use the default optimizer - adam\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    # reduce_on_plateau_patience=1000,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size() / 1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62060260a3f4825beed44f5eaef9e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.011481536214968821\n",
      "Restoring states from the checkpoint path at C:\\Users\\Sathmika\\Desktop\\FYP\\cryptoCurrencyPricePredictionTFT\\cryptoCurrencyPricePredictionTFT\\mainCode\\.lr_find_e0edc34e-4785-4b96-ab96-0158dd33ba2e.ckpt\n",
      "Restored all states from the checkpoint at C:\\Users\\Sathmika\\Desktop\\FYP\\cryptoCurrencyPricePredictionTFT\\cryptoCurrencyPricePredictionTFT\\mainCode\\.lr_find_e0edc34e-4785-4b96-ab96-0158dd33ba2e.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.011481536214968821\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find the optimal learning rate\n",
    "res = Tuner(trainer).lr_find(\n",
    "    tft, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader, max_lr=10.0, min_lr=1e-6\n",
    ")\n",
    "# and plot the result - always visually confirm that the suggested learning rate makes sense\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 25.1k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"cpu\",\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=50,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=2,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    # optimizer=\"Ranger\",\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size() / 1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 0      | train\n",
      "3  | prescalers                         | ModuleDict                      | 176    | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 1.7 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 5.1 K  | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 4.4 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544    | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 808    | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576    | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576    | train\n",
      "20 | output_layer                       | Linear                          | 119    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "25.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.1 K    Total params\n",
      "0.100     Total estimated model params size (MB)\n",
      "420       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de9a7bc08524d0b840a757162f75e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                               | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81db4d699b0c4fe3adb4305d5873983e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25793b3b0f254444ac5c7fe3bb1039f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfafba42ed0431a854928b328b32f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                    | 0/? [00:00<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    570\u001b[0m     ckpt_path,\n\u001b[0;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    573\u001b[0m )\n\u001b[1;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1025\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:250\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[1;32m--> 250\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:190\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[1;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:268\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[1;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:167\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 167\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\core\\module.py:1306\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1304\u001b[0m \n\u001b[0;32m   1305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1306\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\core\\optimizer.py:153\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:238\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[1;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision.py:122\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[1;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m             )\n\u001b[1;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:202\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 202\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision.py:108\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[1;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03mhook is called.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m \n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:144\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:129\u001b[0m, in \u001b[0;36mClosure.closure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[1;32m--> 129\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:317\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    315\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[1;32m--> 317\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:651\u001b[0m, in \u001b[0;36mBaseModel.training_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m    650\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m--> 651\u001b[0m log, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step_outputs\u001b[38;5;241m.\u001b[39mappend(log)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:826\u001b[0m, in \u001b[0;36mBaseModel.step\u001b[1;34m(self, x, y, batch_idx, **kwargs)\u001b[0m\n\u001b[0;32m    825\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 826\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_stage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprog_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecoder_target\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m log \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_lengths\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:533\u001b[0m, in \u001b[0;36mBaseModel.log\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\core\\module.py:525\u001b[0m, in \u001b[0;36mLightningModule.log\u001b[1;34m(self, name, value, prog_bar, logger, on_step, on_epoch, reduce_fx, enable_graph, sync_dist, sync_dist_group, add_dataloader_idx, batch_size, metric_attribute, rank_zero_only)\u001b[0m\n\u001b[0;32m    523\u001b[0m     logger \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 525\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_current_fx_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprog_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprog_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreduce_fx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_fx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_dataloader_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_dataloader_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync_dist\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accelerator_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_distributed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync_dist_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync_dist_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync_dist_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_attribute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_attribute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrank_zero_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrank_zero_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    544\u001b[0m trainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39m_current_fx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_fx_name\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\result.py:414\u001b[0m, in \u001b[0;36m_ResultCollection.log\u001b[1;34m(self, fx, name, value, prog_bar, logger, on_step, on_epoch, reduce_fx, enable_graph, sync_dist, sync_dist_fn, sync_dist_group, add_dataloader_idx, batch_size, metric_attribute, rank_zero_only)\u001b[0m\n\u001b[0;32m    413\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_batch_size(\u001b[38;5;28mself\u001b[39m[key], batch_size, meta)\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\result.py:419\u001b[0m, in \u001b[0;36m_ResultCollection.update_metrics\u001b[1;34m(self, key, value, batch_size)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# performance: avoid calling `__call__` to avoid the checks in `torch.nn.Module._call_impl`\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m \u001b[43mresult_metric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    420\u001b[0m result_metric\u001b[38;5;241m.\u001b[39mhas_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\result.py:270\u001b[0m, in \u001b[0;36m_ResultMetric.forward\u001b[1;34m(self, value, batch_size)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;66;03m# performance: skip the `torch.no_grad` context manager by calling `update` directly\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchmetrics\\metric.py:483\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 483\u001b[0m     \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\result.py:225\u001b[0m, in \u001b[0;36m_ResultMetric.update\u001b[1;34m(self, value, batch_size)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mon_step:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39msync(\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# `clone` because `sync` is in-place\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;66;03m# performance: no need to accumulate on values only logged on_step\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[295], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# fit network\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[0;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[1;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
